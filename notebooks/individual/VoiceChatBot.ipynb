{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a09198-9b2c-4cfa-af41-7a4297694aad",
   "metadata": {},
   "source": [
    "# Voice Chat Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b75af2bc-8bcb-4846-b92a-348a20ac4ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/safuan/Python/AI/venv_ai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "from datasets import load_dataset\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "import warnings\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41ecef75-ae68-43b8-a373-225f91d9d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"neural-bridge/rag-dataset-12000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ba47eef-1360-4e15-823a-f82a9c890e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(question: str, dataset, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Find the most relevant context for a given question in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        question (str): The user's question\n",
    "        dataset: The loaded dataset\n",
    "        threshold (float): Minimum similarity score to consider context relevant\n",
    "        \n",
    "    Returns:\n",
    "        str: The most relevant context if found, otherwise None\n",
    "    \"\"\"\n",
    "    # Create embeddings for all contexts in the dataset\n",
    "    embedding = HuggingFaceEmbeddings()\n",
    "    vectorstore = FAISS.from_texts(\n",
    "        texts=[sample[\"context\"] for sample in dataset],\n",
    "        embedding=embedding\n",
    "    )\n",
    "    \n",
    "    # Get embeddings for the question\n",
    "    question_embedding = embedding.embed_query(question)\n",
    "    \n",
    "    # Search for similar contexts\n",
    "    similarities, context_indices = vectorstore.similarity_search(\n",
    "        question_embedding,\n",
    "        k=1\n",
    "    )\n",
    "    \n",
    "    # Check if we found a relevant context\n",
    "    if similarities[0] >= threshold:\n",
    "        context_idx = context_indices[0]\n",
    "        return dataset[context_idx][\"context\"]\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c27b7-c396-4560-b615-b7781379b1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de546263-9a4e-4838-8b9e-5844f32a9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"neural-bridge/rag-dataset-12000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33f612bd-1be0-4222-a0c6-9e3bdf5c7e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who is the music director of the Quebec Symphony Orchestra?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6e08002-d1da-4669-ae35-411f75833bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HOUSTON (Jan. 23, 2018) – Fabien Gabel, music director of the Quebec Symphony Orchestra, returns to Houston to lead the Houston Symphony in Ravel’s Daphnis and Chloé on Feb. 2 and 3 at 8 p.m. and Feb. 4 at 2:30 p.m. in Jones Hall.\\nRecognized internationally as one of the stars of the new generation, Fabien Gabel is a regular guest of the Houston Symphony and an audience favorite. Known for conducting music with French influences, Gabel leads the Symphony in a program of French and American classics, including the breathtaking musical sunrise from Ravel’s Daphnis and Chloé and Bernstein’s comic operetta Overture to Candide as the Symphony joins other orchestras around the world for Leonard Bernstein at 100, a worldwide celebration of the composer’s 100th birthday. Also on the program is Habanera, a piece by French composer Louis Aubert.\\nThe evening’s featured soloist, Colin Currie, is hailed as “the world’s finest and most daring percussionist” (Spectator). He performs regularly with the world’s leading orchestras and conductors. Currie returns to Houston to perform Conjurer for Percussionist, Strings and Brass by leading American composer John Corigl.\\nRAVEL’S DAPHNIS AND CHLOÉ\\nFriday, Feb. 2, 2018, at 8 p.m.\\nSaturday, Feb. 3, 2018, at 8 p.m.\\nSunday, Feb. 4, 2018, at 2:30 p.m.\\nFabien Gabel, conductor\\nColin Currie, percussion\\nBernstein: Overture to Candide\\nCorigliano: Conjurer for Percussionist, String and Brass\\nIbert: Ports of Call\\nAubert: Habanera\\nRavel: Suite No. 2 from Daphnis and Chloé\\nAbout Fabiel Gabel Français des Jeunes (French Youth Orchestra).\\nFollowing.\\nG. His rapidly-expanding U.S. presence has seen him leading the Cleveland Orchestra, Houston Symphony Orchestra, Detroit Symphony Orchestra, San Diego Symphony Orchestra and more.\\nFabré Hamelin, Beatrice Rana, Gautier Capuçon, and Simone Lamsma, or singers like Jennifer Larmore, Measha Bruggergosman, Danielle de Niese, Natalie Dessay,.\\nAbout Colin Currie\\nHailed as “the world’s finest and most daring percussionist” (Spectator), Colin Currie performs regularly with the world’s leading orchestras and conductors. From his earliest years Currie forged a pioneering path in commissioning and creating new music for percussion. In recognition of this commitment, he received the Royal Philharmonic Society Young Artist Award in 2000, a Borletti-Buitoni Trust Award in 2005 and the Royal Philharmonic Society Instrumentalist Award in 2015. Currie has premiered works. Currie’s 2017-18 season includes premieres of works by Andy Akiho, Sir Harrison Birtwistle, Brett Dean, Joe Duddell and Dave Maric. In the coming seasons Currie will premiere works by Helen Grime and Simon Holt.\\nCurrie currently serves as Artist in Association at London’s Southbank Centre, where he was the focus of a major percussion festival in 2014, and this season Currie completes his three year term as Artist in Residence with the Oregon Symphony Orchestra. The 2017-18 season also features a series of solo recitals at the Schubert Club, Budapest’s Liszt Academy, Lawrence University and Sir James MacMillan’s The Cumnock Tryst Music Festival. Orchestral engagements include performances here and with the Antwerp Symphony, BBC Philharmonic, Het Gelders Orkest, National Youth Orchestra of Scotland and the Scottish Chamber and Brno Contemporary Orchestras.\\nCurrie’s ensemble the Colin Currie Group was formed in 2006 to celebrate the music of Steve Reich and made its five-star debut at the BBC Proms. With Reich’s personal endorsement, Currie and his ensemble have become ambassadors for Reich’s Drumming, a work they have performed many times internationally. The group’s debut recording of Drumming is scheduled for release this season. Currie has recorded many concertos, solos and chamber works, including most recently works by Elliott Carter (Ondine) and Simon Holt (NMC). His recording of Rautavaara’s Incantations with the Helsinki Philharmonic and John Storgårds (Ondine) won a 2012 Gramophone Award, and his recording of Jennifer Higdon’s Percussion Concerto with the London Philharmonic and Marin Alsop won a 2010 Grammy Award.\\nColin Currie plays Zildjan cymbals and is a MarimbaOne Artist. To learn more,\\n###'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afaaa9b5-fab0-43e8-ac47-6f1892684dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# 1. Подготовим данные\n",
    "texts = [sample[\"context\"] for sample in dataset['test']]\n",
    "documents = [Document(page_content=text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f02b18b1-90c2-40b4-868c-74f1b0336a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tr/d1rx7zt15lzgkp2yc1nwbg100000gn/T/ipykernel_19316/245203998.py:7: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedding_model = HuggingFaceEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Получаем контексты и эмбеддинги\n",
    "texts = [sample[\"context\"] for sample in dataset['test']]\n",
    "embedding_model = HuggingFaceEmbeddings()\n",
    "embeddings = [embedding_model.embed_query(text) for text in texts]\n",
    "\n",
    "# Нормализуем векторы вручную\n",
    "normalized_embeddings = normalize(embeddings)  # теперь будет косинусная метрика\n",
    "\n",
    "# Создаём FAISS индекс вручную (в обход from_texts)\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23555a41-6b91-4acf-a986-f3aa4fde627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Создаём FAISS IndexFlatIP (inner product)\n",
    "dimension = len(normalized_embeddings[0])\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(np.array(normalized_embeddings))\n",
    "\n",
    "# 5. Создаём FAISS vectorstore без аргумента texts\n",
    "vectorstore = FAISS(embedding_function=embedding_model, index=index, docstore=None, index_to_docstore_id=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99def0c6-a3c6-47a9-bc83-6f9b3080fa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.vectorstores.faiss.FAISS"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3ce8892-4e6d-4906-b8b9-20ef6019ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "docstore = InMemoryDocstore(dict(enumerate(documents)))\n",
    "vectorstore.docstore = docstore\n",
    "vectorstore.index_to_docstore_id = dict(enumerate(range(len(documents))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4bb7e919-9e7b-4ac1-bc43-1b414f8d285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform similarity search with scores\n",
    "document, score = vectorstore.similarity_search_with_score(\"Who is are you?\", k=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d44f36b-f6bf-4d2f-ac1e-52fb70d7d273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29662287"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9057e47d-4148-4987-b779-9106846d7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_doc, score = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba8e80b6-28c5-4cc5-bd59-93ca78a3c5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I feel compelled to do this. Why? Because I don\\'t want to start working on a new sign right now.\\nI got this at A Yank Gone South. Go read it, won\\'t you?\\nThe Rules:\\n1. Link to the person that tagged you, and post the rules on your blog.\\n2. Share 7 random/weird facts about yourself .\\n3. Tag 7 random people at the end of your post and include links to their blogs. --Yeah, I\\'m not going to do this, but feel free to paste and post it if you want. I\\'m a rebel.\\nRANDOM KELLY STUFF\\n1) I get very irritated when unimportant things begin to get complicated. I like things to be decided on and then carried out. I Can. Not. Stand. to sit around and listen to people waffle about what needs to be done when easy answers are the best answers. This is not to say I am particular about what the answers are, I just want the answer to be decided on without undue talkage about them. If I have an opinion about something, you\\'re gonna dang well hear it, but I\\'m easy going enough to go along with anything most of the time. If you start making a big deal about whatever it is, I\\'m going to start wanting to harm you emotionally. : )\\n2) I have a whole lot of friends, but only a few close ones. I kind of like it that way. It\\'s not that I\\'m against making new friends or meeting new people, but good friends -really good ones, the kind you want to hang out with and tell secrets to- have to click. I really hate it when I\\'m told I \"need\" to meet more people so I can go out and do stuff more often. If I don\\'t feel that specific click with a person, I\\'m ok not being their best buddy and am usually uncomfortable hanging out with them. I can do it, and I will, but I\\'m probably going to end up acting weird and awkward. My circle may be small, but it\\'s quality. At least I believe it is. It\\'s also not exclusive to anyone who isn\\'t already there, so please don\\'t think I\\'m a snob for feeling the way I do. This is probably going to sound cheesy, but finding a really close friend is like finding a piece of your inner puzzle. You know when you meet them. Did any of that make sense?\\n3) I HAVE to push the cart when I go to the grocery store. I don\\'t know why. I won\\'t let Steve touch it if he\\'s with me. It gives me a sense of control in an otherwise crazy world, I guess!\\n4) I can perform in front of really large crowds with no problem. Small crowds unnerve me. I have sung in front of crowds as large as 2,000 and did a fine job. I sang for a group of 12 and sounded like there was an earthquake going on inside of me.\\n5) In a similar vein, one of my most guilty pleasures is to go to those booths where you can record your own CDs and make one. I don\\'t always sound very good, and I very rarely let anyone hear the results, but I love to do it, and have spent way too much time and money on them.\\n6) I buy evening gowns for no reason what so ever. I don\\'t spend a lot on them, but if I find one I like on clearance and I can afford it, I will buy it. At last count I had 5 or 6. Maybe I\\'m just hoping I will get a chance to wear one someday! I\\'m an optimist.\\n7) I wish I could dance. Really dance. Not the kind you do at your prom and corporate Christmas parties, but dance. Tango, waltz, rhumba...all of that stuff. Someday I\\'m determined to learn.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2b2643d-d97b-4c2c-9186-006279fa7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf2bf70f-7908-4f2b-a8ab-42ef605f85db",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseModel.validate() missing 1 required positional argument: 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msimilarities\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseModel.validate() missing 1 required positional argument: 'value'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e885825-e48c-402f-8662-52331d9c7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load the dataset\n",
    "    ds = load_dataset(\"neural-bridge/rag-dataset-12000\")\n",
    "    \n",
    "    console.print(\"[cyan]Assistant starting...\")\n",
    "\n",
    "    if not check_ollama_server():\n",
    "        console.print(\"[red]Please start the Ollama server by running 'ollama serve'\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    console.print(\"[cyan]Assistant ready! Press Enter to start recording, then press Enter again to stop.\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            console.input(\n",
    "                \"Press Enter to start recording, then press Enter again to stop.\"\n",
    "            )\n",
    "\n",
    "            data_queue = Queue()  # type: ignore[var-annotated]\n",
    "            stop_event = threading.Event()\n",
    "            recording_thread = threading.Thread(\n",
    "                target=record_audio,\n",
    "                args=(stop_event, data_queue),\n",
    "            )\n",
    "            recording_thread.start()\n",
    "\n",
    "            input()\n",
    "            stop_event.set()\n",
    "            recording_thread.join()\n",
    "\n",
    "            audio_data = b\"\".join(list(data_queue.queue))\n",
    "            audio_np = (\n",
    "                np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "            )\n",
    "\n",
    "            if audio_np.size > 0:\n",
    "                with console.status(\"Transcribing...\", spinner=\"earth\"):\n",
    "                    text = transcribe(audio_np)\n",
    "                console.print(f\"[yellow]You: {text}\")\n",
    "\n",
    "                # Find relevant context\n",
    "                with console.status(\"Searching for relevant context...\", spinner=\"earth\"):\n",
    "                    context = get_context(text, ds)\n",
    "                    if context:\n",
    "                        console.print(f\"[green]Found helpful context: {context}\")\n",
    "                        # Add context to the prompt template\n",
    "                        text = f\"{text}\\n\\nContext: {context}\"\n",
    "\n",
    "                with console.status(\"Generating response...\", spinner=\"earth\"):\n",
    "                    response = get_llm_response(text)\n",
    "                    sample_rate, audio_array = tts.long_form_synthesize(response)\n",
    "\n",
    "                console.print(f\"[cyan]Assistant: {response}\")\n",
    "                play_audio(sample_rate, audio_array)\n",
    "            else:\n",
    "                console.print(\n",
    "                    \"[red]No audio recorded. Please ensure your microphone is working.\"\n",
    "                )\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        console.print(\"\\n[red]Exiting...\")\n",
    "\n",
    "    console.print(\"[blue]Session ended.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my env ai",
   "language": "python",
   "name": "myenv_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# NLP project

# ☁️ Cloud group members:
- Safuan IUSUPOV
- Shodai FUJIMOTO
- Dorsa MOTIALLAH
- Darkhan ISLAM
- Hadjer BRIOUA 

# Project Summary

1.   📚 Retrieval-Augmented Generation (RAG) Dataset 12000
2.   📗 Embedding Analysis Overview (Word2Vec)
3.   📕 Semantic analysis of dataset (by Sentence Transformer)
4.   📙 Semantic analysis (by LLM embeddings)
5.   🤖 Classical NLP approach
6.   📐 RAG Metrics
7.   🧾 Prompt Engineering with Gemini 2.0 Flash
8.   🚂 LLMs in RAG and their Fine-Tuning
9.   📘 Summarization Model with LoRA and PEFT using FLAN-T5
10.  🎙️ Voice Interactive Chatbot (Offline LLM + Contextual RAG) 🦙

# 📚 [Retrieval-Augmented Generation (RAG) Dataset 12000](https://huggingface.co/datasets/neural-bridge/rag-dataset-12000)

Retrieval-Augmented Generation (RAG) Dataset 12000 is an English dataset designed for RAG-optimized models, built by [Neural Bridge AI](https://www.neuralbridge.ai/), and released under [Apache license 2.0](https://www.apache.org/licenses/LICENSE-2.0.html).

## Dataset Description


### Dataset Summary

Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by allowing them to consult an external authoritative knowledge base before generating responses. This approach significantly boosts the models' ability to produce relevant, accurate, and context-specific output by extending their capabilities to specialized domains or an organization's internal data, without the need for retraining. RAG offers a cost-effective method to leverage the vast data processing power of LLMs, equipped with billions of parameters, for tasks such as question-answering, language translation, and sentence completion, ensuring that the output is always up-to-date and applicable to various contexts.

RAG's importance lies in its potential to address the inherent challenges of LLMs, such as unpredictability in responses, reliance on static and potentially outdated training data, and the risk of disseminating incorrect or non-authoritative information. These issues can negatively affect user trust in AI-powered applications, making RAG's ability to guide LLMs toward authoritative sources for information retrieval invaluable.

RAG has multiple benefits, including cost-effective implementation and maintenance, access to current information, improved user trust through accurate information and source attribution, and greater control for developers over the information retrieval process. This approach allows for the dynamic updating of LLMs with the latest research, statistics, or news, directly addressing the challenges of maintaining relevancy and accuracy in rapidly changing knowledge landscapes. Additionally, it empowers organizations to deploy generative AI more confidently across a wider range of applications, enhancing both the user experience and the reliability of AI-driven interactions.

Retrieval-Augmented Generation (RAG) Dataset 12000 dataset is a triple-feature collection, with each entry containing a "context", "question", and "answer" fields, designed to help build RAG-optimized models. This data consists of 12000 entries, and the context data is from [Falcon RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb).

### Dataset Structure

- **Languages**: English (`en`)
- **Size**: 12,000 entries
- **Splits**:
  - Train: 9,600 examples
  - Test: 2,400 examples
- **Fields**:
  - `context`: A string consisting of a range of tokens.
  - `question`: A string consisting of a question related to the context.
  - `answer`: A string consisting of an answer for the question.

Each data point comprises a context obtained from Falcon RefinedWeb, a question about the context, and an answer for the question. The question and answer for each data point are generated by GPT-4.

# 📗 Embedding Analysis Overview (Word2Vec)

This notebook explores various techniques for analyzing textual data through word embeddings. The key components include:

- **Word2Vec**: To generate vector representations of words based on their context.
- **t-SNE**: For dimensionality reduction and visualization of high-dimensional embeddings in 2D space.
- **Cosine Similarity**: To measure the semantic similarity between `context`, `question`, and `answer` fields.
- **K-Means Clustering**: To group semantically similar text samples based on their embeddings.

The goal is to understand semantic patterns in the dataset by embedding, comparing, and clustering natural language components.

## Data Preprocessing

To prepare the text data for embedding, we apply several preprocessing steps:

- **Email and URL removal**: Strip out any email addresses and hyperlinks using regular expressions.
- **Punctuation removal**: Clean text from punctuation symbols.
- **Lowercasing**: Standardize all text to lowercase for consistency.
- **Tokenization**: Split text into individual words using NLTK's `RegexpTokenizer`.
- **Stopword removal**: Eliminate common English stopwords (e.g., "the", "and", "is") using NLTK.
- **Missing value removal**: Drop rows that contain missing (`NaN`) entries to ensure data integrity.

These transformations are applied to the `context`, `question`, and `answer` fields of the dataset.


